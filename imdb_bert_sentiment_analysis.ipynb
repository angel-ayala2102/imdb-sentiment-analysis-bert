{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto y objetivo del proyecto\n",
    "\n",
    "Film Junky Union, una comunidad enfocada en el análisis de películas clásicas, busca desarrollar un sistema automático para **clasificar reseñas de películas según su polaridad**.\n",
    "\n",
    "El objetivo de este proyecto es **entrenar un modelo de procesamiento de lenguaje natural (NLP)** capaz de identificar reseñas negativas a partir de texto, utilizando un conjunto de datos de reseñas de IMDB etiquetadas como positivas o negativas.\n",
    "\n",
    "El desempeño del modelo se evalúa mediante la métrica **F1-score**, la cual debe alcanzar un valor mínimo de **0.85**, de acuerdo con los requisitos del proyecto.\n",
    "\n",
    "### Nota sobre el uso de BERT\n",
    "\n",
    "Adicionalmente, se incluye un modelo basado en **embeddings de BERT** como aproximación avanzada de NLP.\n",
    "\n",
    "Debido a las limitaciones de procesamiento en CPU, el entrenamiento y evaluación de este modelo se realizaron utilizando únicamente **200 ejemplos de entrenamiento y 200 de prueba**, siguiendo las recomendaciones del curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM37GBfKcfQG"
   },
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mZWeUUicfQG"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5F6uMNZCcfQH"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "# la siguiente línea proporciona gráficos de mejor calidad en pantallas HiDPI\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZ2SAMLMcfQI"
   },
   "outputs": [],
   "source": [
    "# esto es para usar progress_apply, puedes leer más en https://pypi.org/project/tqdm/#pandas-integration\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tg3kq8x5cfQI"
   },
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usmHLWsAcfQI"
   },
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv('/datasets/imdb_reviews.tsv', sep='\\t', dtype={'votes': 'Int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kSyldQYcfQI"
   },
   "outputs": [],
   "source": [
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1mr76qYcfQJ"
   },
   "outputs": [],
   "source": [
    "print(df_reviews['ds_part'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pj5RiIeacfQJ"
   },
   "outputs": [],
   "source": [
    "print(df_reviews['pos'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisar valores ausentes\n",
    "df_reviews.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisar filas duplicadas\n",
    "df_reviews.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9lnR-SFcfQJ"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN3s-pfGcfQJ"
   },
   "source": [
    "Veamos el número de películas y reseñas a lo largo de los años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFlfkDwicfQJ",
    "outputId": "5e03f6d1-24fe-422b-89c6-ddb140c0e9e2"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "ax = axs[0]\n",
    "\n",
    "dft1 = df_reviews[['tconst', 'start_year']].drop_duplicates() \\\n",
    "    ['start_year'].value_counts().sort_index()\n",
    "dft1 = dft1.reindex(index=np.arange(dft1.index.min(), max(dft1.index.max(), 2021))).fillna(0)\n",
    "dft1.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Número de películas a lo largo de los años')\n",
    "\n",
    "ax = axs[1]\n",
    "\n",
    "dft2 = df_reviews.groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft2 = dft2.reindex(index=np.arange(dft2.index.min(), max(dft2.index.max(), 2021))).fillna(0)\n",
    "\n",
    "dft2.plot(kind='bar', stacked=True, label='#reviews (neg, pos)', ax=ax)\n",
    "\n",
    "dft2 = df_reviews['start_year'].value_counts().sort_index()\n",
    "dft2 = dft2.reindex(index=np.arange(dft2.index.min(), max(dft2.index.max(), 2021))).fillna(0)\n",
    "dft3 = (dft2/dft1).fillna(0)\n",
    "axt = ax.twinx()\n",
    "dft3.reset_index(drop=True).rolling(5).mean().plot(color='orange', label='reviews per movie (avg over 5 years)', ax=axt)\n",
    "\n",
    "lines, labels = axt.get_legend_handles_labels()\n",
    "ax.legend(lines, labels, loc='upper left')\n",
    "\n",
    "ax.set_title('Número de reseñas a lo largo de los años')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Número de películas a lo largo de los años**\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "Se observa un crecimiento progresivo en el número de películas a lo largo del tiempo, con un aumento especialmente marcado a partir de la segunda mitad del siglo XX. Este comportamiento sugiere una expansión de la industria cinematográfica y una mayor disponibilidad de títulos en los años más recientes. En los primeros años, la cantidad de películas es muy reducida, lo cual es consistente con el desarrollo temprano del cine.\n",
    "\n",
    "**Número de reseñas a lo largo de los años**\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "El número total de reseñas crece de forma significativa en los años más recientes, lo cual está alineado con el aumento en la cantidad de películas y con la popularización de plataformas digitales para dejar opiniones. La línea de promedio móvil de reseñas por película muestra una tendencia general al alza, lo que indica que, además de haber más películas, los usuarios participan más activamente dejando reseñas por título."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Spw-miGycfQK"
   },
   "source": [
    "Veamos la distribución del número de reseñas por película con el conteo exacto y KDE (solo para saber cómo puede diferir del conteo exacto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "favsoXXccfQK",
    "outputId": "928574e9-d932-4d47-c3d9-285384542570"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "ax = axs[0]\n",
    "dft = df_reviews.groupby('tconst')['review'].count() \\\n",
    "    .value_counts() \\\n",
    "    .sort_index()\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_title('Gráfico de barras de #Reseñas por película')\n",
    "\n",
    "ax = axs[1]\n",
    "dft = df_reviews.groupby('tconst')['review'].count()\n",
    "sns.kdeplot(dft, ax=ax)\n",
    "ax.set_title('Gráfico KDE de #Reseñas por película')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribución del número de reseñas por película (barras y KDE)**\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "La distribución muestra que la mayoría de las películas cuentan con un número reducido de reseñas, mientras que solo un pequeño grupo de títulos concentra una gran cantidad de opiniones. Esto genera una distribución asimétrica con una cola larga hacia la derecha, lo cual es común en datos de popularidad. El gráfico KDE refuerza esta observación al mostrar una alta densidad en valores bajos y una disminución gradual conforme aumenta el número de reseñas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tr85g2MVcfQL",
    "outputId": "238dcebc-c9cb-4849-a638-e5d6eab31cc1"
   },
   "outputs": [],
   "source": [
    "df_reviews['pos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RkqoFx_cfQL",
    "outputId": "1c07ac81-cac4-409d-c32f-c7dfaaa07f6a"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax = axs[0]\n",
    "dft = df_reviews.query('ds_part == \"train\"')['rating'].value_counts().sort_index()\n",
    "dft = dft.reindex(index=np.arange(min(dft.index.min(), 1), max(dft.index.max(), 11))).fillna(0)\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_ylim([0, 5000])\n",
    "ax.set_title('El conjunto de entrenamiento: distribución de puntuaciones')\n",
    "\n",
    "ax = axs[1]\n",
    "dft = df_reviews.query('ds_part == \"test\"')['rating'].value_counts().sort_index()\n",
    "dft = dft.reindex(index=np.arange(min(dft.index.min(), 1), max(dft.index.max(), 11))).fillna(0)\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_ylim([0, 5000])\n",
    "ax.set_title('El conjunto de prueba: distribución de puntuaciones')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribución de puntuaciones en el conjunto de entrenamiento y prueba**\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "Las distribuciones de puntuaciones en los conjuntos de entrenamiento y prueba son muy similares, lo que indica que la separación de los datos se realizó de manera adecuada. En ambos casos se observa una mayor concentración de puntuaciones extremas, especialmente en valores altos, lo que sugiere que los usuarios tienden a dejar reseñas muy positivas o muy negativas, en lugar de valoraciones neutrales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-NDbAxNcfQL"
   },
   "source": [
    "Distribución de reseñas negativas y positivas a lo largo de los años para dos partes del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBeyt8qzcfQL",
    "outputId": "4e898688-bc01-43cb-faf3-ad1b90f08216"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(16, 8), gridspec_kw=dict(width_ratios=(2, 1), height_ratios=(1, 1)))\n",
    "\n",
    "ax = axs[0][0]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"train\"').groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft.index = dft.index.astype('int')\n",
    "dft = dft.reindex(index=np.arange(dft.index.min(), max(dft.index.max(), 2020))).fillna(0)\n",
    "dft.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set_title('El conjunto de entrenamiento: número de reseñas de diferentes polaridades por año')\n",
    "\n",
    "ax = axs[0][1]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"train\"').groupby(['tconst', 'pos'])['pos'].count().unstack()\n",
    "sns.kdeplot(dft[0], color='blue', label='negative', kernel='epa', ax=ax)\n",
    "sns.kdeplot(dft[1], color='green', label='positive', kernel='epa', ax=ax)\n",
    "ax.legend()\n",
    "ax.set_title('El conjunto de entrenamiento: distribución de diferentes polaridades por película')\n",
    "\n",
    "ax = axs[1][0]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"test\"').groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft.index = dft.index.astype('int')\n",
    "dft = dft.reindex(index=np.arange(dft.index.min(), max(dft.index.max(), 2020))).fillna(0)\n",
    "dft.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set_title('El conjunto de prueba: número de reseñas de diferentes polaridades por año')\n",
    "\n",
    "ax = axs[1][1]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"test\"').groupby(['tconst', 'pos'])['pos'].count().unstack()\n",
    "sns.kdeplot(dft[0], color='blue', label='negative', kernel='epa', ax=ax)\n",
    "sns.kdeplot(dft[1], color='green', label='positive', kernel='epa', ax=ax)\n",
    "ax.legend()\n",
    "ax.set_title('El conjunto de prueba: distribución de diferentes polaridades por película')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Número de reseñas positivas y negativas por año (train)**\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "En el conjunto de entrenamiento se aprecia un aumento considerable en el número de reseñas tanto positivas como negativas con el paso del tiempo. Sin embargo, las reseñas positivas predominan de forma consistente, lo que indica un ligero desbalance de clases. Este comportamiento es relevante para el modelado, ya que puede influir en el desempeño de los modelos de clasificación.\n",
    "\n",
    "**Distribución de polaridades por película (train)**\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "La distribución muestra que, en promedio, las películas tienden a recibir más reseñas positivas que negativas. No obstante, ambas polaridades presentan una cola larga, lo que indica que existen películas con una gran cantidad de reseñas negativas o positivas. Esta variabilidad sugiere que el contenido de las reseñas es diverso y que el modelo deberá aprender a distinguir patrones lingüísticos más allá de la frecuencia.\n",
    "\n",
    "**Número de reseñas positivas y negativas por año (test)**\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "El conjunto de prueba presenta un patrón muy similar al del conjunto de entrenamiento, tanto en la evolución temporal como en la proporción entre reseñas positivas y negativas. Esto confirma que el conjunto de prueba es representativo del comportamiento general de los datos y permite evaluar el modelo de forma confiable.\n",
    "\n",
    "**Distribución de polaridades por película (test)**\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "Al igual que en el conjunto de entrenamiento, la distribución de polaridades por película en el conjunto de prueba muestra una mayor densidad de reseñas positivas. La similitud entre ambas distribuciones refuerza la consistencia de la partición de datos y reduce el riesgo de sesgos durante la evaluación del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFyhz3HWcfQM"
   },
   "source": [
    "## Procedimiento de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpGf22xycfQM"
   },
   "source": [
    "Composición de una rutina de evaluación que se pueda usar para todos los modelos en este proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTBNDqB_cfQM"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "def evaluate_model(model, train_features, train_target, test_features, test_target):\n",
    "\n",
    "    eval_stats = {}\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "    for type, features, target in (('train', train_features, train_target), ('test', test_features, test_target)):\n",
    "\n",
    "        eval_stats[type] = {}\n",
    "\n",
    "        pred_target = model.predict(features)\n",
    "        pred_proba = model.predict_proba(features)[:, 1]\n",
    "\n",
    "\n",
    "        # F1\n",
    "        f1_thresholds = np.arange(0, 1.01, 0.05)\n",
    "        f1_scores = [metrics.f1_score(target, pred_proba>=threshold) for threshold in f1_thresholds]\n",
    "\n",
    "        # ROC\n",
    "        fpr, tpr, roc_thresholds = metrics.roc_curve(target, pred_proba)\n",
    "        roc_auc = metrics.roc_auc_score(target, pred_proba)\n",
    "        eval_stats[type]['ROC AUC'] = roc_auc\n",
    "\n",
    "        # PRC\n",
    "        precision, recall, pr_thresholds = metrics.precision_recall_curve(target, pred_proba)\n",
    "        aps = metrics.average_precision_score(target, pred_proba)\n",
    "        eval_stats[type]['APS'] = aps\n",
    "\n",
    "        if type == 'train':\n",
    "            color = 'blue'\n",
    "        else:\n",
    "            color = 'green'\n",
    "\n",
    "        # Valor F1\n",
    "        ax = axs[0]\n",
    "        max_f1_score_idx = np.argmax(f1_scores)\n",
    "        ax.plot(f1_thresholds, f1_scores, color=color, label=f'{type}, max={f1_scores[max_f1_score_idx]:.2f} @ {f1_thresholds[max_f1_score_idx]:.2f}')\n",
    "        # establecer cruces para algunos umbrales\n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(f1_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "            ax.plot(f1_thresholds[closest_value_idx], f1_scores[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.set_xlim([-0.02, 1.02])\n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('threshold')\n",
    "        ax.set_ylabel('F1')\n",
    "        ax.legend(loc='lower center')\n",
    "        ax.set_title(f'Valor F1')\n",
    "\n",
    "        # ROC\n",
    "        ax = axs[1]\n",
    "        ax.plot(fpr, tpr, color=color, label=f'{type}, ROC AUC={roc_auc:.2f}')\n",
    "        # establecer cruces para algunos umbrales\n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(roc_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "            ax.plot(fpr[closest_value_idx], tpr[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "        ax.set_xlim([-0.02, 1.02])\n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('FPR')\n",
    "        ax.set_ylabel('TPR')\n",
    "        ax.legend(loc='lower center')\n",
    "        ax.set_title(f'Curva ROC')\n",
    "\n",
    "        # PRC\n",
    "        ax = axs[2]\n",
    "        ax.plot(recall, precision, color=color, label=f'{type}, AP={aps:.2f}')\n",
    "        # establecer cruces para algunos umbrales\n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(pr_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "            ax.plot(recall[closest_value_idx], precision[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.set_xlim([-0.02, 1.02])\n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('recall')\n",
    "        ax.set_ylabel('precision')\n",
    "        ax.legend(loc='lower center')\n",
    "        ax.set_title(f'PRC')\n",
    "\n",
    "        eval_stats[type]['Accuracy'] = metrics.accuracy_score(target, pred_target)\n",
    "        eval_stats[type]['F1'] = metrics.f1_score(target, pred_target)\n",
    "\n",
    "    df_eval_stats = pd.DataFrame(eval_stats)\n",
    "    df_eval_stats = df_eval_stats.round(2)\n",
    "    df_eval_stats = df_eval_stats.reindex(index=('Accuracy', 'F1', 'APS', 'ROC AUC'))\n",
    "\n",
    "    print(df_eval_stats)\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2QcpCPpcfQN"
   },
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HuGs01qcfQN"
   },
   "source": [
    "Suponemos que todos los modelos a continuación aceptan textos en minúsculas y sin dígitos, signos de puntuación, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxcGV0v0cfQN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# creamos una función para limpiar texto\n",
    "import re\n",
    "\n",
    "def clear_text(text):\n",
    "    pattern = r\"[^A-Za-z']\"\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "df_reviews['review_norm'] = df_reviews['review'].apply(clear_text)\n",
    "\n",
    "# No hacemos la conversión a minúsculas aquí debido a que es mejor hacerlo más adelante, al lematizar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFLVNj9GcfQN"
   },
   "source": [
    "## División entrenamiento / prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4mIx2RBcfQN"
   },
   "source": [
    "Por fortuna, todo el conjunto de datos ya está dividido en partes de entrenamiento/prueba; 'ds_part' es el indicador correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_ghGy0icfQN",
    "outputId": "53a1ab2e-ef13-42e6-d9a5-3446069db818"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_reviews_train = df_reviews.query('ds_part == \"train\"').copy()\n",
    "df_reviews_test = df_reviews.query('ds_part == \"test\"').copy()\n",
    "\n",
    "target_train = df_reviews_train['pos']\n",
    "target_test = df_reviews_test['pos']\n",
    "\n",
    "print(df_reviews_train.shape)\n",
    "print(df_reviews_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ICBFHsjcfQN"
   },
   "source": [
    "## Trabajar con modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXm9IdrLcfQO"
   },
   "source": [
    "### Modelo 0 - Constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2WRy_ZucfQO"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEF-UYsGcfQO"
   },
   "outputs": [],
   "source": [
    "features_train_dummy = np.zeros((len(target_train), 1))\n",
    "features_test_dummy = np.zeros((len(target_test), 1))\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dummy.fit(features_train_dummy, target_train)\n",
    "\n",
    "evaluate_model(dummy, features_train_dummy, target_train, features_test_dummy, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuYWGBKBcfQO"
   },
   "source": [
    "### Modelo 1 - NLTK, TF-IDF y LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgoQwY4rcfQQ"
   },
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SA8Q9A9wcfQQ"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88hKBTl6cfQQ"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words_nltk = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# tokenización y lematización avanzada con nltk\n",
    "lemmatizer  = WordNetLemmatizer()\n",
    "\n",
    "def tokenize_lemmatize_nltk(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "# creamos la columna de características lematizadas con nltk en los conjuntos de entrenamiento y prueba\n",
    "df_reviews_train['review_lemma_nltk'] = df_reviews_train['review_norm'].apply(tokenize_lemmatize_nltk)\n",
    "df_reviews_test['review_lemma_nltk'] = df_reviews_test['review_norm'].apply(tokenize_lemmatize_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujWoCzbwcfQQ"
   },
   "outputs": [],
   "source": [
    "# creamos el vectorizador para el modelo con nltk\n",
    "tfidf_vectorizer_nltk = TfidfVectorizer(stop_words=stop_words_nltk, lowercase=False, ngram_range=(1, 2))\n",
    "# creamos features_train y features_test para el modelo con nltk\n",
    "train_corpus_nltk = df_reviews_train['review_lemma_nltk']\n",
    "features_train_nltk = tfidf_vectorizer_nltk.fit_transform(train_corpus_nltk)\n",
    "\n",
    "test_corpus_nltk = df_reviews_test['review_lemma_nltk']\n",
    "features_test_nltk = tfidf_vectorizer_nltk.transform(test_corpus_nltk)\n",
    "\n",
    "# creamos y entrenamos el modelo\n",
    "lr_nltk = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_nltk.fit(features_train_nltk, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aO0ZqZ16cfQQ"
   },
   "outputs": [],
   "source": [
    "# probamos el modelo\n",
    "evaluate_model(lr_nltk, features_train_nltk, target_train, features_test_nltk, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teD9phjPcfQQ"
   },
   "source": [
    "### Modelo 2 - spaCy, TF-IDF y LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEoEV9oGcfQR"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "stop_words_spacy = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EkP85DpacfQR"
   },
   "outputs": [],
   "source": [
    "# tokenización y lematización avanzada con spaCy\n",
    "def tokenize_lemmatize_spacy(text):\n",
    "\n",
    "    doc = nlp(text.lower())\n",
    "    #tokens = [token.lemma_ for token in doc if not token.is_stop] (alternativa(eliminaríamos la variable stop_words_spacy))\n",
    "    tokens = [token.lemma_ for token in doc]\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# creamos la columna de características lematizadas con spaCy en los conjuntos de entrenamiento y prueba\n",
    "df_reviews_train['review_lemma_spacy'] = df_reviews_train['review_norm'].apply(tokenize_lemmatize_spacy)\n",
    "df_reviews_test['review_lemma_spacy'] = df_reviews_test['review_norm'].apply(tokenize_lemmatize_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkBym00-cfQR"
   },
   "outputs": [],
   "source": [
    "# creamos el vectorizador para el modelo con spaCy\n",
    "tfidf_vectorizer_spacy = TfidfVectorizer(stop_words=stop_words_spacy, lowercase=False, ngram_range=(1, 2))\n",
    "# creamos features_train y features_test para el modelo con spaCy\n",
    "train_corpus_spacy = df_reviews_train['review_lemma_spacy']\n",
    "features_train_spacy = tfidf_vectorizer_spacy.fit_transform(train_corpus_spacy)\n",
    "\n",
    "test_corpus_spacy = df_reviews_test['review_lemma_spacy']\n",
    "features_test_spacy = tfidf_vectorizer_spacy.transform(test_corpus_spacy)\n",
    "\n",
    "# creamos y entrenamos el modelo\n",
    "lr_spacy = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_spacy.fit(features_train_spacy, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wk2NkxWDcfQR"
   },
   "outputs": [],
   "source": [
    "# probamos el modelo\n",
    "evaluate_model(lr_spacy, features_train_spacy, target_train, features_test_spacy, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ccJH__fcfQR"
   },
   "outputs": [],
   "source": [
    "print(features_train_nltk.shape, features_test_nltk.shape)\n",
    "print(features_train_spacy.shape, features_test_spacy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0VlSM5YcfQR"
   },
   "source": [
    "### Modelo 3 - spaCy, TF-IDF y LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAE0JqmdcfQR"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHOkVoQQcfQR"
   },
   "outputs": [],
   "source": [
    "# usaremos exactamente los mismos datos vectorizados del modelo anterior\n",
    "# creamos y entrenamos el modelo\n",
    "lgbm_spacy = LGBMClassifier(random_state=42, n_estimators=200, learning_rate=0.1)\n",
    "lgbm_spacy.fit(features_train_spacy, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oq6FV6MccfQS"
   },
   "outputs": [],
   "source": [
    "# probamos el modelo\n",
    "evaluate_model(lgbm_spacy, features_train_spacy, target_train, features_test_spacy, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlQhUM51cfQS"
   },
   "source": [
    "###  Modelo 9 - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9HAU_V-cfQS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fn8vtxEdcfQS"
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = transformers.BertConfig.from_pretrained('bert-base-uncased')\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZZvlCcdcfQS"
   },
   "outputs": [],
   "source": [
    "# VERSIÓN ORIGINAL\n",
    "\n",
    "# def BERT_text_to_embeddings(texts, max_length=512, batch_size=100, force_device=None, disable_progress_bar=False):\n",
    "\n",
    "#    enc = tokenizer(\n",
    "#        texts.tolist() if hasattr(texts, \"tolist\") else texts,\n",
    "#        add_special_tokens=True, padding='max_length',\n",
    "#        truncation=True,\n",
    "#        max_length=max_length,\n",
    "#        return_attention_mask=True)\n",
    "#    \n",
    "#    ids_list = enc['input_ids']\n",
    "#    attention_mask_list = enc['attention_mask']\n",
    "\n",
    "\n",
    "#    if force_device is not None:\n",
    "#        device = torch.device(force_device)\n",
    "#    else:\n",
    "#        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#    model.to(device)\n",
    "#    if not disable_progress_bar:\n",
    "#        print(f'Uso del dispositivo {device}.')\n",
    "\n",
    "    # obtener insertados en lotes\n",
    "    \n",
    "#    embeddings = []\n",
    "#    model.eval()\n",
    "#    for i in tqdm(range(math.ceil(len(ids_list)/batch_size)), disable=disable_progress_bar):\n",
    "#        ids_batch = torch.LongTensor(ids_list[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "#        attention_mask_batch = torch.LongTensor(attention_mask_list[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "\n",
    "#        with torch.no_grad():\n",
    "#            batch_embeddings = model(input_ids=ids_batch, attention_mask=attention_mask_batch)\n",
    "#        embeddings.append(batch_embeddings.last_hidden_state[:,0,:].detach().cpu().numpy())\n",
    "\n",
    "#    return np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTA: La versión original de esta función (comentada arriba) tokenizaba todo el corpus antes de procesarlo.\n",
    "# Sin embargo, en este entorno el kernel se reiniciaba por falta de memoria al manejar listas muy grandes.\n",
    "# Por eso, usamos esta versión \"streaming\", que procesa los textos por lotes sin cargar todo a la RAM.\n",
    "# La lógica es la misma, solo optimiza el uso de memoria.\n",
    "\n",
    "\n",
    "def BERT_text_to_embeddings(texts, max_length=256, batch_size=8, force_device=None, disable_progress_bar=False):\n",
    "    # Asegura lista de strings (si viene como Series)\n",
    "    texts = texts.tolist() if hasattr(texts, \"tolist\") else texts\n",
    "\n",
    "    # Selección de dispositivo\n",
    "    device = torch.device(force_device) if force_device is not None else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    if not disable_progress_bar:\n",
    "        print(f'Uso del dispositivo {device}.')\n",
    "\n",
    "    embeddings = []\n",
    "    total = len(texts)\n",
    "\n",
    "    # Procesa por lotes: tokeniza y pasa por el modelo SIN mantener todo en RAM\n",
    "    for i in tqdm(range(0, total, batch_size), disable=disable_progress_bar):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "        enc = tokenizer(\n",
    "            batch_texts,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'     # <- clave: devuelve tensores PyTorch directamente\n",
    "        )\n",
    "\n",
    "        input_ids = enc['input_ids'].to(device)\n",
    "        attention_mask = enc['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            cls = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "        embeddings.append(cls)\n",
    "\n",
    "    return np.concatenate(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentamos cargar embeddings ya calculados para evitar recalcular BERT\n",
    "try:\n",
    "    with np.load('features_bert.npz') as data:\n",
    "        features_train_bert = data['features_train_bert']\n",
    "        features_test_bert = data['features_test_bert']\n",
    "    print(\"Embeddings BERT cargados desde archivo features_bert.npz.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"features_bert.npz no existe. Generando embeddings con BERT (200 train / 200 test)...\")\n",
    "    features_train_bert = BERT_text_to_embeddings(df_reviews_train['review_norm'][:200])\n",
    "    features_test_bert = BERT_text_to_embeddings(df_reviews_test['review_norm'][:200])\n",
    "\n",
    "    np.savez_compressed(\n",
    "        'features_bert.npz',\n",
    "        features_train_bert=features_train_bert,\n",
    "        features_test_bert=features_test_bert\n",
    "    )\n",
    "    print(\"Embeddings guardados en features_bert.npz.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7_j9A3RcfQT"
   },
   "outputs": [],
   "source": [
    "# ¡Atención! La ejecución de BERT para miles de textos puede llevar mucho tiempo en la CPU, al menos varias horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SX-B1Nx3cfQT"
   },
   "outputs": [],
   "source": [
    "print(df_reviews_train['review_norm'].shape)\n",
    "print(features_train_bert.shape)\n",
    "print(target_train.shape)\n",
    "print()\n",
    "print(df_reviews_test['review_norm'].shape)\n",
    "print(features_test_bert.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORIOeTPIcfQU"
   },
   "outputs": [],
   "source": [
    "# creamos y entrenamos el modelo\n",
    "lr_bert = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_bert.fit(features_train_bert, target_train.iloc[:features_train_bert.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBTKE_eXcfQU"
   },
   "outputs": [],
   "source": [
    "# probamos el modelo\n",
    "evaluate_model(lr_bert, features_train_bert, target_train.iloc[:features_train_bert.shape[0]], features_test_bert, target_test.iloc[:features_test_bert.shape[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpLOym4JcfQU"
   },
   "source": [
    "## Mis reseñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JizwXLEGcfQU"
   },
   "outputs": [],
   "source": [
    "# puedes eliminar por completo estas reseñas y probar tus modelos en tus propias reseñas; las que se muestran a continuación son solo ejemplos\n",
    "\n",
    "my_reviews = pd.DataFrame([\n",
    "    'I did not simply like it, not my kind of movie.',\n",
    "    'Well, I was bored and felt asleep in the middle of the movie.',\n",
    "    'I was really fascinated with the movie',\n",
    "    'Even the actors looked really old and disinterested, and they got paid to be in the movie. What a soulless cash grab.',\n",
    "    'I didn\\'t expect the reboot to be so good! Writers really cared about the source material',\n",
    "    'The movie had its upsides and downsides, but I feel like overall it\\'s a decent flick. I could see myself going to see it again.',\n",
    "    'What a rotten attempt at a comedy. Not a single joke lands, everyone acts annoying and loud, even kids won\\'t like this!',\n",
    "    'Launching on Netflix was a brave move & I really appreciate being able to binge on episode after episode, of this exciting intelligent new drama.'\n",
    "], columns=['review'])\n",
    "\n",
    "\"\"\"\n",
    "my_reviews = pd.DataFrame([\n",
    "    'Simplemente no me gustó, no es mi tipo de película.',\n",
    "    'Bueno, estaba aburrido y me quedé dormido a media película.',\n",
    "    'Estaba realmente fascinada con la película',\n",
    "    'Hasta los actores parecían muy viejos y desinteresados, y les pagaron por estar en la película. Qué robo tan desalmado.',\n",
    "    '¡No esperaba que el relanzamiento fuera tan bueno! Los escritores realmente se preocuparon por el material original',\n",
    "    'La película tuvo sus altibajos, pero siento que, en general, es una película decente. Sí la volvería a ver',\n",
    "    'Qué pésimo intento de comedia. Ni una sola broma tiene sentido, todos actúan de forma irritante y ruidosa, ¡ni siquiera a los niños les gustará esto!',\n",
    "    'Fue muy valiente el lanzamiento en Netflix y realmente aprecio poder seguir viendo episodio tras episodio de este nuevo drama tan emocionante e inteligente.'\n",
    "], columns=['review'])\n",
    "\"\"\"\n",
    "\n",
    "my_reviews['review_norm'] = my_reviews['review'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mT_niSv7cfQU"
   },
   "source": [
    "### Modelo 1 (LR+NLTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el corpus normalizado\n",
    "corpus_norm = my_reviews['review_norm']\n",
    "# hacemos tokenización y lematización avanzada con nltk\n",
    "my_reviews['review_lemma_nltk'] = corpus_norm.apply(tokenize_lemmatize_nltk)\n",
    "corpus_lemma_nltk = my_reviews['review_lemma_nltk']\n",
    "# creamos las features con nltk\n",
    "my_reviews_features_nltk = tfidf_vectorizer_nltk.transform(corpus_lemma_nltk)\n",
    "# obtenemos las probabilidades de que cada reseña sea positiva\n",
    "my_reviews_pred_proba_lr_nltk = lr_nltk.predict_proba(my_reviews_features_nltk)[:, 1]\n",
    "# mostramos cada reseña con su probabilidad de ser positiva\n",
    "for i, review in enumerate(corpus_norm.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_proba_lr_nltk[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8Gn5GJ-cfQV"
   },
   "source": [
    "### Modelo 2 (LR+spaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el corpus normalizado\n",
    "corpus_norm = my_reviews['review_norm']\n",
    "# hacemos tokenización y lematización avanzada con spacy\n",
    "my_reviews['review_lemma_spacy'] = corpus_norm.apply(tokenize_lemmatize_spacy)\n",
    "corpus_lemma_spacy = my_reviews['review_lemma_spacy']\n",
    "# creamos las features con spacy\n",
    "my_reviews_features_spacy = tfidf_vectorizer_spacy.transform(corpus_lemma_spacy)\n",
    "# obtenemos las probabilidades de que cada reseña sea positiva\n",
    "my_reviews_pred_proba_lr_spacy = lr_spacy.predict_proba(my_reviews_features_spacy)[:, 1]\n",
    "# mostramos cada reseña con su probabilidad de ser positiva\n",
    "for i, review in enumerate(corpus_norm.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_proba_lr_spacy[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4jdHbHocfQV"
   },
   "source": [
    "### Modelo 3 (LGBMClassifier+spaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota: en este paso no repetimos la lematización ni la vectorización, ya que este modelo usa las mismas features TF-IDF creadas para el modelo anterior.\n",
    "\n",
    "# obtenemos las probabilidades de que cada reseña sea positiva\n",
    "my_reviews_pred_proba_lgbm_spacy = lgbm_spacy.predict_proba(my_reviews_features_spacy)[:, 1]\n",
    "# mostramos cada reseña con su probabilidad de ser positiva\n",
    "for i, review in enumerate(corpus_norm.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_proba_lgbm_spacy[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1NGuHk6cfQV"
   },
   "source": [
    "### Modelo BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos las features con BERT\n",
    "my_reviews_features_bert = BERT_text_to_embeddings(corpus_norm, disable_progress_bar=False)\n",
    "# obtenemos las probabilidades de que cada reseña sea positiva\n",
    "my_reviews_pred_proba_bert = lr_bert.predict_proba(my_reviews_features_bert)[:, 1]\n",
    "# mostramos cada reseña con su probabilidad de ser positiva\n",
    "for i, review in enumerate(corpus_norm.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_proba_bert[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CyDGAfwcfQW"
   },
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz5mKqducfQW"
   },
   "source": [
    "**Modelo Logistic Regression + NLTK**\n",
    "\n",
    "Este modelo muestra un rendimiento excelente, con valores de F1 y ROC AUC muy altos tanto en entrenamiento como en prueba. La pequeña diferencia entre ambos conjuntos indica que el modelo generaliza bien y no presenta sobreajuste significativo. Esto demuestra que el modelo ha aprendido correctamente las relaciones entre las palabras y el sentimiento de las reseñas, interpretando de forma precisa tanto los textos positivos como los negativos.\n",
    "\n",
    "**Modelo Logistic Regression + spaCy**\n",
    "\n",
    "Este modelo obtuvo resultados muy similares al de NLTK, apenas ligeramente menores en el conjunto de prueba. Esto sugiere que ambas estrategias de procesamiento del lenguaje (NLTK y spaCy) son igualmente efectivas para este corpus, y que el rendimiento depende más de la representación TF-IDF y el modelo lineal que de la librería usada para la lematización.\n",
    "\n",
    "**Modelo LGBMClassifier + spaCy**\n",
    "\n",
    "Este modelo también logra un rendimiento alto, aunque ligeramente inferior al de la regresión logística. Esto puede deberse a que los modelos de tipo árbol como LightGBM requieren más datos para superar a los modelos lineales en tareas de texto, donde los vectores TF-IDF suelen ser muy dispersos. Aun así, su rendimiento sigue siendo sólido y demuestra que puede capturar bien las relaciones no lineales en las reseñas.\n",
    "\n",
    "**Modelo BERT**\n",
    "\n",
    "Este modelo sí mostró claramente un sobreajuste, al alcanzar un F1 de 100 % en entrenamiento, y un 75% en el conjunto de prueba. Esto puede deberse a que los embeddings se generaron a partir de solo 200 reseñas, lo que limita la capacidad de generalización del modelo. A pesar de ello, el modelo aún logra predicciones razonables en el conjunto de prueba, mostrando el potencial de BERT incluso con datos limitados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_AegW5GcfQW"
   },
   "source": [
    "**Mis reseñas**\n",
    "\n",
    "Al aplicar los modelos entrenados a mis reseñas, podemos observar que cada uno asigna una probabilidad de positividad distinta a los textos.\n",
    "En general, con los modelos NLTK y spaCy, las reseñas con un tono claramente positivo tienden a recibir valores más altos (por encima de 0.6), mientras que las reseñas con un tono negativo suelen tener valores más bajos (por debajo de 0.4). LGBM varía un poco más, pero sigue la misma tendencia.\n",
    "\n",
    "Sin embargo, hay algunos casos donde el modelo asigna probabilidades intermedias o contradictorias (por ejemplo, frases positivas con valores menores a 0.5), lo que indica que no siempre interpreta correctamente el tono emocional o el contexto del texto. Esto es normal, ya que las probabilidades reflejan la confianza del modelo, no necesariamente la verdad objetiva. BERT se comporta más errático con pocas muestras, lo cual confirma su sobreajuste por datos limitados.\n",
    "\n",
    "En conjunto, las probabilidades permiten observar qué tan seguro está el modelo de que cada reseña sea positiva o negativa, y sirven para entender el comportamiento del modelo en textos nuevos."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ac629f305345b17df6668bc9b17021b4f12075c260532782c34ed55a489bc20f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
